# Cells Classification

## Introduction:

For machine learning, you can get excellent performance with great parameters for every network as long as `having enough data and calculated power`. However, people do not have such a huge useful dataset for many regions like medical domains. This makes the problem that how to use available information thoroughly an important question. 

For some pathologists, classifying cells’ types is a big part of their work. This is a kind of `simple work` for people if you have knowledge of each types’ characteristics. But `boring` sometimes. In this project, I used `categorical cross-entropy` to train a network for cells type `classification`. Cells in the dataset are tumor, TIL, and normal stromal cells. After training, the network can figure each cell picture as input (in specified size), and give the label of its type. 

However, `the dataset is limited`. Real pathologists are very busy in their daily life. So, it is hard to get a huge amount of labeled pictures. This project aims to find the influence of `manipulating datasets` for network performance. Which is how to use the limited dataset to get better performance of networks. The manipulation could be data augmentation or pre-processing of images used before training. 

## Method:
In paper [1], the method that `normalizes images in color space` to erase the objective difference caused by machines. Also, `rotation` and `flipping` are good ways to increase datasets using limited information. In article [2], though it’s for radiology, a method of `windowing different organs` arose. Images of this project are all cells not organs, however. I was thinking about whether extracting the nucleus feature of cells is feasible (pathologists may identify cell types by recognizing nucleus or finding mitosis). According to that, I split the nucleus and other tissues apart to black and white separately, which is like a kind of  `ultra-windowing` (only keeping the nucleus part in black). In paper [3], `translating pictures (shifting)` and `adding noise` are inspired me. In this project, two kinds of methods for enhancing network performance using limited datasets are discussed -- data Augmentation and data preprocessing.

## Settings

### 1.	segmentation of test dataset and verification dataset.
The verification dataset was set for 1500 images, each type has 500 pictures (each type of cell accounts for one-third). The number 1500 is decided through several tests (result in appendix), making sure that the network can improve performance. Meanwhile, there’s enough data for training. The verification dataset has 1500 images. The same as training data. The verification dataset has no overlap with training data. For every method below, the original training dataset, as well as the verification dataset, did not change. This is for the variable control, to find the influence of methods.
### 2.	Software for manipulation.
All the methods related to image processing are finished by MATLAB. No external package was used. 
### 3.	Evaluation criterion.
In this project, the final performance of the deep learning network is evaluated by the Micro-AUC generated by the test dataset. In each method, a curve formed by original network performance vs manipulated network shows the influence (all listed in the appendix) of the method. the highest AUC was selected to evaluate the performance and saved for testing. 

## File details and test result:

* You can find every image processing code in fold mfile
* Test result and more method details are in the report.pdf
